{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6ZVc8afQtDpz",
        "outputId": "4f73054c-2a04-4057-9d16-1ebee8e9b141"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Dataset loaded successfully!\n",
            "Columns: ['id', 'source', 'title', 'image', 'url', 'content', 'date', 'embedding', 'created_at', 'updated_at', 'summary']\n",
            "   id source                                              title  \\\n",
            "0  83  tempo  Depo Plumpang Terbakar, Anggota DPR Minta Pert...   \n",
            "1  84  tempo  Jokowi Perintahkan Wapres Ma'ruf Amin Tinjau L...   \n",
            "2  85  tempo  HNW Mendukung Jamaah Umroh First Travel Dapatk...   \n",
            "3  86  tempo  Tim Dokkes Polri Telah Terima 14 Kantong Jenaz...   \n",
            "4  87  tempo  Bamsoet Ajak Komunitas Otomotif Kembangkan Per...   \n",
            "\n",
            "                                               image  \\\n",
            "0  https://statik.tempo.co/data/2023/03/04/id_118...   \n",
            "1  https://statik.tempo.co/data/2023/03/04/id_118...   \n",
            "2  https://statik.tempo.co/data/2023/03/04/id_118...   \n",
            "3  https://statik.tempo.co/data/2023/03/04/id_118...   \n",
            "4  https://statik.tempo.co/data/2023/03/04/id_118...   \n",
            "\n",
            "                                                 url  \\\n",
            "0  https://nasional.tempo.co/read/1698528/depo-pl...   \n",
            "1  https://nasional.tempo.co/read/1698522/jokowi-...   \n",
            "2  https://nasional.tempo.co/read/1698527/hnw-men...   \n",
            "3  https://nasional.tempo.co/read/1698540/tim-dok...   \n",
            "4  https://nasional.tempo.co/read/1698536/bamsoet...   \n",
            "\n",
            "                                             content                    date  \\\n",
            "0  TEMPO.CO, Jakarta - Anggota Komisi VII DPR RI ...  2023-03-04 06:18:13+00   \n",
            "1  TEMPO.CO, Jakarta - Presiden Joko Widodo atau ...  2023-03-04 06:04:38+00   \n",
            "2  INFO NASIONAL - Wakil Ketua MPR RI Dr. H. M. H...  2023-03-04 06:18:04+00   \n",
            "3  TEMPO.CO, Jakarta - Tim Kedokteran dan Kesehat...  2023-03-04 06:44:10+00   \n",
            "4  INFO NASIONAL - Ketua MPR RI sekaligus Ketua U...  2023-03-04 06:38:57+00   \n",
            "\n",
            "                                           embedding  \\\n",
            "0  [-0.01590039,-0.034130897,0.005732614,-0.01853...   \n",
            "1  [-0.017608976,-0.021786924,0.01547983,-0.00932...   \n",
            "2  [0.00841488,-0.023665192,0.006762431,-0.013723...   \n",
            "3  [-0.012671886,-0.0039057182,0.019575326,-0.016...   \n",
            "4  [-0.015486176,-0.0125719,-0.0122843925,-0.0343...   \n",
            "\n",
            "                   created_at                  updated_at  \\\n",
            "0  2023-03-04 07:03:39.039332  2023-03-04 07:03:39.039332   \n",
            "1  2023-03-04 07:03:39.039332  2023-03-04 07:03:39.039332   \n",
            "2  2023-03-04 07:03:39.039332  2023-03-04 07:03:39.039332   \n",
            "3  2023-03-04 07:03:39.039332  2023-03-04 07:03:39.039332   \n",
            "4  2023-03-04 07:03:39.039332  2023-03-04 07:03:39.039332   \n",
            "\n",
            "                                             summary  \n",
            "0  Anggota Komisi VII DPR RI Rofik Hananto menyay...  \n",
            "1  Presiden Joko Widodo telah memerintahkan Wakil...  \n",
            "2  Wakil Ketua MPR RI Dr. H. M. Hidayat Nur Wahid...  \n",
            "3  Tim Kedokteran dan Kesehatan (Dokkes) Polri te...  \n",
            "4  Ketua MPR RI Bambang Soesatyo telah diangkat s...  \n",
            "\n",
            "âœ… Columns renamed:\n",
            "                                                text  label\n",
            "0  Depo Plumpang Terbakar, Anggota DPR Minta Pert...  tempo\n",
            "1  Jokowi Perintahkan Wapres Ma'ruf Amin Tinjau L...  tempo\n",
            "2  HNW Mendukung Jamaah Umroh First Travel Dapatk...  tempo\n",
            "3  Tim Dokkes Polri Telah Terima 14 Kantong Jenaz...  tempo\n",
            "4  Bamsoet Ajak Komunitas Otomotif Kembangkan Per...  tempo\n",
            "\n",
            "ğŸ§¹ Cleaned text sample:\n",
            "                                                  text     label\n",
            "456  pangkat polisi syarat tamtama menjadi bintara ...     tempo\n",
            "22       upaya pemerataan pembangunan lewat pariwisata     tempo\n",
            "355  bamsoet maklumi bobbyprasetyo mundur dari form...  kumparan\n",
            "\n",
            "ğŸ“Š Label Summary:\n",
            "cnbcindonesia        -> 96 samples\n",
            "cnnindonesia         -> 104 samples\n",
            "kumparan             -> 6 samples\n",
            "okezone              -> 7 samples\n",
            "tempo                -> 335 samples\n",
            "\n",
            "âœ… Tokenization complete!\n",
            "Train shape: (438, 200), Test shape: (110, 200)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_max_pooling1d            â”‚ ?                      â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)               â”‚ ?                      â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_max_pooling1d            â”‚ ?                      â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               â”‚ ?                      â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 277ms/step - accuracy: 0.3523 - loss: 1.5695 - val_accuracy: 0.5909 - val_loss: 1.3711\n",
            "Epoch 2/6\n",
            "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 187ms/step - accuracy: 0.6002 - loss: 1.2479 - val_accuracy: 0.5909 - val_loss: 1.1472\n",
            "Epoch 3/6\n",
            "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 213ms/step - accuracy: 0.6137 - loss: 1.0527 - val_accuracy: 0.5909 - val_loss: 1.1971\n",
            "Epoch 4/6\n",
            "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 311ms/step - accuracy: 0.5925 - loss: 1.0407 - val_accuracy: 0.5909 - val_loss: 1.1578\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6301 - loss: 1.0316\n",
            "\n",
            "ğŸ¯ Test Accuracy: 60.91%\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step\n",
            "\n",
            "ğŸ“° Sample Prediction: Jokowi meresmikan proyek pembangunan di Jakarta\n",
            "Predicted Label: tempo\n"
          ]
        }
      ],
      "source": [
        "# =====================================================\n",
        "# CNN TEXT CLASSIFICATION â€” INDONESIAN NEWS DATASET\n",
        "# =====================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# =====================================================\n",
        "# 1. LOAD DATASET SAFELY\n",
        "# =====================================================\n",
        "\n",
        "file_path = \"/content/data.csv\"   # ğŸ“ Change to your dataset path\n",
        "\n",
        "try:\n",
        "    df = pd.read_csv(file_path, engine='python', on_bad_lines='skip', encoding='utf-8')\n",
        "except:\n",
        "    df = pd.read_csv(file_path, engine='python', on_bad_lines='skip', encoding='latin1')\n",
        "\n",
        "print(\"âœ… Dataset loaded successfully!\")\n",
        "print(\"Columns:\", list(df.columns))\n",
        "print(df.head())\n",
        "\n",
        "# =====================================================\n",
        "# 2. RENAME COLUMNS MANUALLY\n",
        "# =====================================================\n",
        "# ğŸ‘‰ Update these names based on your dataset\n",
        "# Example: if your file has columns ['judul_berita', 'kategori']\n",
        "# then set: text_col = 'judul_berita', label_col = 'kategori'\n",
        "\n",
        "text_col = 'title'   # <-- change this to your text column\n",
        "label_col = 'source'      # <-- change this to your label column\n",
        "\n",
        "df = df.rename(columns={text_col: 'text', label_col: 'label'})\n",
        "df = df[['text', 'label']].dropna().reset_index(drop=True)\n",
        "\n",
        "print(\"\\nâœ… Columns renamed:\")\n",
        "print(df.head())\n",
        "\n",
        "# =====================================================\n",
        "# 3. CLEAN & PREPROCESS TEXT\n",
        "# =====================================================\n",
        "\n",
        "def clean_text(text):\n",
        "    text = str(text).lower()\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)   # remove punctuation/numbers\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # remove multiple spaces\n",
        "    return text\n",
        "\n",
        "df['text'] = df['text'].apply(clean_text)\n",
        "print(\"\\nğŸ§¹ Cleaned text sample:\")\n",
        "print(df.sample(3))\n",
        "\n",
        "# =====================================================\n",
        "# 4. ENCODE LABELS\n",
        "# =====================================================\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "df['label_encoded'] = label_encoder.fit_transform(df['label'])\n",
        "num_classes = len(label_encoder.classes_)\n",
        "\n",
        "print(\"\\nğŸ“Š Label Summary:\")\n",
        "for label, idx in zip(label_encoder.classes_, range(num_classes)):\n",
        "    count = len(df[df['label_encoded'] == idx])\n",
        "    print(f\"{label:20s} -> {count} samples\")\n",
        "\n",
        "# =====================================================\n",
        "# 5. TRAIN-TEST SPLIT\n",
        "# =====================================================\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df['text'], df['label_encoded'],\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=df['label_encoded']\n",
        ")\n",
        "\n",
        "# =====================================================\n",
        "# 6. TOKENIZATION & PADDING\n",
        "# =====================================================\n",
        "\n",
        "max_words = 10000   # Vocabulary size\n",
        "max_len = 200       # Sequence length\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len, padding='post', truncating='post')\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len, padding='post', truncating='post')\n",
        "\n",
        "y_train_cat = to_categorical(y_train, num_classes=num_classes)\n",
        "y_test_cat = to_categorical(y_test, num_classes=num_classes)\n",
        "\n",
        "print(\"\\nâœ… Tokenization complete!\")\n",
        "print(f\"Train shape: {X_train_pad.shape}, Test shape: {X_test_pad.shape}\")\n",
        "\n",
        "# =====================================================\n",
        "# 7. BUILD CNN MODEL\n",
        "# =====================================================\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=max_words, output_dim=128, input_length=max_len),\n",
        "    Conv1D(filters=128, kernel_size=5, activation='relu'),\n",
        "    GlobalMaxPooling1D(),\n",
        "    Dropout(0.5),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# =====================================================\n",
        "# 8. TRAIN MODEL\n",
        "# =====================================================\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_pad, y_train_cat,\n",
        "    epochs=6,\n",
        "    batch_size=64,\n",
        "    validation_split=0.2,\n",
        "    verbose=1,\n",
        "    callbacks=[early_stop]\n",
        ")\n",
        "\n",
        "# =====================================================\n",
        "# 9. EVALUATE MODEL\n",
        "# =====================================================\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_pad, y_test_cat, verbose=1)\n",
        "print(f\"\\nğŸ¯ Test Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# =====================================================\n",
        "# 10. TEST A SAMPLE SENTENCE\n",
        "# =====================================================\n",
        "\n",
        "sample_text = [\"Jokowi meresmikan proyek pembangunan di Jakarta\"]\n",
        "seq = tokenizer.texts_to_sequences(sample_text)\n",
        "pad = pad_sequences(seq, maxlen=max_len)\n",
        "pred = model.predict(pad)\n",
        "pred_label = label_encoder.inverse_transform([np.argmax(pred)])\n",
        "\n",
        "print(f\"\\nğŸ“° Sample Prediction: {sample_text[0]}\")\n",
        "print(f\"Predicted Label: {pred_label[0]}\")"
      ]
    }
  ]
}